# Cloudkoffer 2026

Ein portabler Big Data Cluster auf 5 Intel NUCs fÃ¼r Demos, Workshops und Entwicklung.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         CLOUDKOFFER 2026                                â”‚
â”‚                                                                         â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚   â”‚  node0  â”‚ â”‚  node1  â”‚ â”‚  node2  â”‚ â”‚  node3  â”‚ â”‚  node4  â”‚          â”‚
â”‚   â”‚   DNS   â”‚ â”‚  Master â”‚ â”‚  Worker â”‚ â”‚  Worker â”‚ â”‚  Worker â”‚          â”‚
â”‚   â”‚Grafana  â”‚ â”‚   ZK    â”‚ â”‚   ZK    â”‚ â”‚   ZK    â”‚ â”‚  Solr   â”‚          â”‚
â”‚   â”‚Promethe.â”‚ â”‚  Solr   â”‚ â”‚  Solr   â”‚ â”‚  Solr   â”‚ â”‚  Spark  â”‚          â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚        â”‚           â”‚           â”‚           â”‚           â”‚                â”‚
â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚
â”‚                          Gigabit Switch                                 â”‚
â”‚                               â”‚                                         â”‚
â”‚                        â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”                                  â”‚
â”‚                        â”‚ EdgeRouter X â”‚â”€â”€â”€â”€ Internet                    â”‚
â”‚                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Was ist das?

Der **Cloudkoffer** ist ein kompletter Big Data Stack in einem transportablen Koffer:

- **5 Intel NUCs** mit je 32 GB RAM, 4 Cores, NVMe SSD
- **EdgeRouter X** fÃ¼r Netzwerk und DHCP
- **Gigabit Switch** fÃ¼r interne Kommunikation
- Alles in einem Koffer verstaut

### Einsatzzwecke

- ğŸ“Š **Demos** - Big Data Technologien live zeigen
- ğŸ“ **Workshops** - Hands-on Training ohne Cloud-AbhÃ¤ngigkeit
- ğŸ§ª **Entwicklung** - Lokaler Cluster fÃ¼r Tests
- ğŸ¢ **Offline-Umgebungen** - Funktioniert ohne Internet

---

## Technologie-Stack

### Datenverarbeitung

| Komponente | Beschreibung | Nodes |
|------------|--------------|-------|
| [Apache Solr](https://solr.apache.org/) | Volltextsuche & Analytics | node1-4 |
| [Apache Spark](https://spark.apache.org/) | Verteilte Datenverarbeitung | node1-4 |
| [Apache ZooKeeper](https://zookeeper.apache.org/) | Cluster-Koordination | node1-3 |

### Monitoring

| Komponente | Beschreibung | Node |
|------------|--------------|------|
| [Prometheus](https://prometheus.io/) | Metriken-Sammlung | node0 |
| [Grafana](https://grafana.com/) | Dashboards & Visualisierung | node0 |
| Node Exporter | System-Metriken | alle |

### Infrastruktur

| Komponente | Beschreibung |
|------------|--------------|
| Ubuntu 24.04 LTS | Betriebssystem |
| Cloud-Init | Automatische Konfiguration |
| dnsmasq | DNS fÃ¼r `cloud.local` Domain |
| OpenJDK 17 | Java Runtime |

---

## Architektur-Konzepte

### Warum ZooKeeper?

ZooKeeper ist das "Gehirn" des Clusters:
- **Leader Election** - Wer ist der aktive Solr-Leader?
- **Konfiguration** - Cluster-weite Einstellungen zentral
- **Koordination** - Verteilte Locks und Synchronisation

> 3 Nodes = Quorum mÃ¶glich, toleriert 1 Ausfall

### Warum Solr Cloud?

Verteilte Suche mit:
- **Sharding** - Daten auf mehrere Nodes verteilen
- **Replikation** - Ausfallsicherheit durch Kopien
- **Near Real-Time** - Dokumente sofort durchsuchbar

### Warum Spark?

Verteilte Datenverarbeitung:
- **In-Memory** - Schneller als Hadoop MapReduce
- **SQL** - Spark SQL fÃ¼r Analytics
- **Streaming** - Echtzeit-Verarbeitung mÃ¶glich
- **Solr-Integration** - Daten direkt in Solr indexieren

---

## Netzwerk

| Node | IP | Hostname | Rolle |
|------|-----|----------|-------|
| node0 | 192.168.1.100 | node0.cloud.local | DNS, Monitoring |
| node1 | 192.168.1.101 | node1.cloud.local | ZK, Solr, Spark Master |
| node2 | 192.168.1.102 | node2.cloud.local | ZK, Solr, Spark Worker |
| node3 | 192.168.1.103 | node3.cloud.local | ZK, Solr, Spark Worker |
| node4 | 192.168.1.104 | node4.cloud.local | Solr, Spark Worker |

- **Router**: 192.168.1.1 (EdgeRouter X)
- **Domain**: cloud.local
- **DHCP**: Statische Zuweisung per MAC-Adresse

---

## Quick Start

### 1. Cluster aufsetzen

```bash
cd baremetal

# Konfiguration generieren
./01-generate-configs/generate-all.sh

# Bootbares ISO erstellen
./02-create-iso/create-iso.sh

# Auf USB-Stick schreiben
./03-write-usb/write-usb.sh /dev/sdX

# Jeden NUC vom USB booten (F10)
# Nach Installation: Post-Install pro Node
./04-post-install/apply-cloud-init.sh 192.168.1.100
./04-post-install/apply-cloud-init.sh 192.168.1.101
# ... usw.
```

### 2. Cluster validieren

```bash
./baremetal/09-smoke-tests/smoke-tests.sh
```

### 3. Zugriff auf Services

| Service | URL |
|---------|-----|
| Solr Admin | http://node1.cloud.local:8983/solr/ |
| Spark Master | http://node1.cloud.local:8081/ |
| Grafana | http://node0.cloud.local:3000/ |
| Prometheus | http://node0.cloud.local:9090/ |
| JupyterLab | http://node0.cloud.local:8888/ |

---

## Dokumentation

| Dokument | Inhalt |
|----------|--------|
| [BAREMETAL-SETUP.md](BAREMETAL-SETUP.md) | Ubuntu Installation, Cloud-Init |
| [SOLR-SPARK-SETUP.md](SOLR-SPARK-SETUP.md) | ZooKeeper, Solr, Spark Konfiguration |
| [MONITORING-SETUP.md](MONITORING-SETUP.md) | Prometheus, Grafana, Exporter |
| [baremetal/README.md](baremetal/README.md) | Schritt-fÃ¼r-Schritt Anleitung |

---

## Verzeichnisstruktur

```
Cloudkoffer-2026/
â”œâ”€â”€ README.md                    â† Du bist hier
â”œâ”€â”€ BAREMETAL-SETUP.md           # OS-Installation Doku
â”œâ”€â”€ SOLR-SPARK-SETUP.md          # Big Data Stack Doku
â”œâ”€â”€ MONITORING-SETUP.md          # Monitoring Doku
â”‚
â””â”€â”€ baremetal/                   # Installations-Scripts
    â”œâ”€â”€ 00-edgerouter-config/    # Router Backup & Restore
    â”œâ”€â”€ 01-generate-configs/     # Autoinstall generieren
    â”œâ”€â”€ 02-create-iso/           # Bootbares ISO erstellen
    â”œâ”€â”€ 03-write-usb/            # ISO auf USB schreiben
    â”œâ”€â”€ 04-post-install/         # Node-spezifische Konfig
    â”œâ”€â”€ 05-install-zookeeper/    # ZooKeeper Cloud-Init
    â”œâ”€â”€ 06-install-solr/         # Solr Cloud-Init
    â”œâ”€â”€ 07-install-spark/        # Spark Cloud-Init
    â”œâ”€â”€ 08-install-monitoring/   # Prometheus/Grafana Cloud-Init
    â”œâ”€â”€ 09-smoke-tests/          # Cluster-Validierung
    â””â”€â”€ 10-create-solr-collection/ # Solr Collection anlegen
```

---

## Credentials

| Service | User | Passwort |
|---------|------|----------|
| SSH | cloudadmin | (nur SSH-Key) |
| Grafana | admin | admin (beim ersten Login Ã¤ndern) |

---

## FAQ

### Warum kein Kubernetes?

**Kurz:** Overhead ohne Nutzen fÃ¼r diesen Use Case.

| Aspekt | Kubernetes | Unser Ansatz |
|--------|------------|--------------|
| **KomplexitÃ¤t** | Control Plane, etcd, CNI, Ingress, ... | Direkter Zugriff auf Services |
| **Ressourcen** | ~2-4 GB RAM nur fÃ¼r K8s selbst | Alles fÃ¼r Solr/Spark verfÃ¼gbar |
| **Debugging** | Pod-Logs, kubectl, Service-Mesh | SSH + journalctl + tail -f |
| **Startup-Zeit** | Minuten (Scheduling, Pulls) | Sekunden (systemd) |
| **Lernkurve** | Steil fÃ¼r Workshop-Teilnehmer | Linux-Basics reichen |

Kubernetes lÃ¶st Probleme, die wir nicht haben:
- **Horizontal Scaling** â†’ Wir haben feste 5 Nodes
- **Rolling Deployments** â†’ Demo-Cluster, kein Prod
- **Multi-Tenancy** â†’ Single Purpose System
- **Cloud Portability** â†’ LÃ¤uft im Koffer, nicht in AWS

> *"Use the simplest thing that could possibly work."* - Ward Cunningham

### Macht dieser Aufbau 2026 noch Sinn?

**Ja, gerade 2026!** Hier ist warum:

#### 1. Edge Computing ist relevanter denn je
- Nicht alles gehÃ¶rt in die Cloud
- Latenz, Datenschutz, Offline-FÃ¤higkeit
- Der Cloudkoffer ist ein Edge-Cluster zum Anfassen

#### 2. Die Technologien sind ausgereift
- **Solr 9.x** - 20+ Jahre Entwicklung, battle-tested
- **Spark 3.x** - De-facto Standard fÃ¼r Big Data
- **ZooKeeper** - BewÃ¤hrt in Netflix, LinkedIn, Twitter
- Kein Hype, sondern solide Werkzeuge

#### 3. Hands-on Learning schlÃ¤gt Theorie
- Cloud-Consoles abstrahieren zu viel
- Hier siehst du: Config-Files, Logs, Prozesse
- Fehler sind sichtbar und debugbar

#### 4. UnabhÃ¤ngigkeit von Cloud-Anbietern
- Kein AWS/Azure/GCP Account nÃ¶tig
- Keine laufenden Kosten
- Funktioniert ohne Internet (nach Setup)

### Warum Cloud-Init?

Cloud-Init ist der **Industriestandard** fÃ¼r Server-Provisioning:

#### Vorteile

| Feature | Vorteil |
|---------|---------|
| **Deklarativ** | YAML beschreibt Zielzustand, nicht Schritte |
| **Idempotent** | Mehrfach ausfÃ¼hren = gleiches Ergebnis |
| **Universell** | AWS, Azure, GCP, OpenStack, Bare Metal |
| **Einfach** | Keine Agents, keine Server, kein Master |

#### Alternativen und warum nicht

| Tool | Warum nicht |
|------|-------------|
| **Ansible** | Braucht SSH-Zugang + Control Node. Cloud-Init lÃ¤uft *vor* dem ersten Boot. |
| **Puppet/Chef** | Agent-basiert, Server nÃ¶tig, Overkill fÃ¼r 5 Nodes |
| **Terraform** | FÃ¼r Infrastruktur-Provisioning, nicht OS-Config |
| **Shell Scripts** | Nicht idempotent, fehleranfÃ¤llig, schwer wartbar |

#### So nutzen wir Cloud-Init

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   USB-Stick Boot    â”‚
â”‚   (Autoinstall)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  user-data (YAML)   â”‚â”€â”€â”€â”€â–¶â”‚  Ubuntu installiert â”‚
â”‚  - Locale, Keyboard â”‚     â”‚  - SSH ready        â”‚
â”‚  - User + SSH-Key   â”‚     â”‚  - /data erstellt   â”‚
â”‚  - /etc/hosts       â”‚     â”‚  - Basis-System     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                       â”‚
                                       â–¼
                            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                            â”‚  Post-Install       â”‚
                            â”‚  (Cloud-Init YAML)  â”‚
                            â”‚  - Pakete           â”‚
                            â”‚  - Services         â”‚
                            â”‚  - Konfiguration    â”‚
                            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

Cloud-Init ist die richtige Wahl, weil es:
- Im Ubuntu-Installer bereits integriert ist
- Keine zusÃ¤tzliche Infrastruktur braucht
- Reproduzierbare Ergebnisse liefert
- In 5 Minuten verstÃ¤ndlich ist

---

## Lizenz

Internes Projekt - nicht zur VerÃ¶ffentlichung bestimmt.
